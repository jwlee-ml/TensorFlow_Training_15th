{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "3_2.Training_Neural_Networks.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnzCRlUxUysg",
        "colab_type": "text"
      },
      "source": [
        "# Training Neural Networks\n",
        "\n",
        "이번 실습에서는 neural network을 training하는데 사용되는 여러가지 방법들에 대해서 실습해보고,\n",
        "\n",
        "이러한 방법들을 이용하여 MNIST dataset의 성능을 어디까지 올릴 수 있는지 도전해보도록 하겠습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKGXDfkXUysj",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CweL1g6Uysk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d3304e34-f189-4aa0-e8ed-c2d74e327dbb"
      },
      "source": [
        "## Google Colab에서 TensorFlow 2.x 버전을 사용하기 위해서는 아래 magic command를 수행하면 간편하게 할 수 있습니다\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_OLmD3KUysn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "18a4b6a4-9e65-4fbc-f635-655665ef5ec8"
      },
      "source": [
        "## 필요한 Library들을 import 합니다\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "## TensorFlow, Keras version 확인\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTmeu9TLUysr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(777)\n",
        "tf.random.set_seed(777)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ_oEC8wUysu",
        "colab_type": "text"
      },
      "source": [
        "## Coding Tips\n",
        "\n",
        "#### 1. Hyper Paramter 정하기\n",
        "#### 2. Data 준비(불러오기 or download 등)\n",
        "#### 3. Dataset 구성 (tf.data.Dataset 이용)\n",
        "#### 4. Modlel 만들기 (Neural Network model)\n",
        "#### 5. Loss function 정의, Optimizer 선택\n",
        "#### 6. Training (Train, Test function 만들기 포함)\n",
        "#### 7. Validation(or Test) 결과 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbBoegT6Uysv",
        "colab_type": "text"
      },
      "source": [
        "## 3-Layer Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsvMKN1CUysw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Hyper-parameters\n",
        "learning_rate = 0.001\n",
        "N_EPOCHS = 30\n",
        "N_BATCH = 100\n",
        "N_CLASS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnMX4ZaMUysz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## MNIST Dataset #########################################################\n",
        "mnist = keras.datasets.mnist\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "##########################################################################\n",
        "\n",
        "## Fashion MNIST Dataset #################################################\n",
        "#mnist = keras.datasets.fashion_mnist\n",
        "#class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "##########################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0akilm0Uys3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7a69330f-c24a-4126-837a-08fad4107d18"
      },
      "source": [
        "## MNIST dataset load\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-nU_KQHUys6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_TRAIN = train_images.shape[0]\n",
        "N_TEST = test_images.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTN15qF8Uys9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## image를 0~1사이 값으로 만들기 위하여 255로 나누어줌\n",
        "train_images = train_images.astype(np.float32) / 255.\n",
        "test_images = test_images.astype(np.float32) / 255.\n",
        "\n",
        "## one-hot encoding\n",
        "train_labels = keras.utils.to_categorical(train_labels, N_CLASS)\n",
        "test_labels = keras.utils.to_categorical(test_labels, N_CLASS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cobgxbyUytA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## dataset 구성    \n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(\n",
        "                buffer_size=100000).batch(N_BATCH).repeat()\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(N_BATCH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moUH42HSUytD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## model function\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2STY-n0aUytG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "outputId": "b11f08c3-48c2-4b8e-ee3b-806d759b997c"
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C1IIWj6UytJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "44ae80b2-a87f-4876-9985-02e6c94dcc97"
      },
      "source": [
        "## Parameters for training\n",
        "steps_per_epoch = N_TRAIN//N_BATCH\n",
        "validation_steps = N_TEST//N_BATCH\n",
        "print(steps_per_epoch, validation_steps)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qorvRydSUytL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9dc4dccc-2a24-4bfd-8f54-ceafcc02c973"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.2493 - accuracy: 0.9281 - val_loss: 0.1119 - val_accuracy: 0.9654\n",
            "Epoch 2/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0940 - accuracy: 0.9713 - val_loss: 0.0824 - val_accuracy: 0.9744\n",
            "Epoch 3/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0624 - accuracy: 0.9812 - val_loss: 0.0790 - val_accuracy: 0.9745\n",
            "Epoch 4/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.0726 - val_accuracy: 0.9772\n",
            "Epoch 5/30\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0335 - accuracy: 0.9896 - val_loss: 0.0698 - val_accuracy: 0.9783\n",
            "Epoch 6/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0761 - val_accuracy: 0.9787\n",
            "Epoch 7/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 0.0802 - val_accuracy: 0.9777\n",
            "Epoch 8/30\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0899 - val_accuracy: 0.9751\n",
            "Epoch 9/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.0829 - val_accuracy: 0.9792\n",
            "Epoch 10/30\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.0821 - val_accuracy: 0.9778\n",
            "Epoch 11/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0795 - val_accuracy: 0.9808\n",
            "Epoch 12/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0798 - val_accuracy: 0.9806\n",
            "Epoch 13/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.0785 - val_accuracy: 0.9827\n",
            "Epoch 14/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0088 - accuracy: 0.9968 - val_loss: 0.0867 - val_accuracy: 0.9804\n",
            "Epoch 15/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.0883 - val_accuracy: 0.9792\n",
            "Epoch 16/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0858 - val_accuracy: 0.9823\n",
            "Epoch 17/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0981 - val_accuracy: 0.9787\n",
            "Epoch 18/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1353 - val_accuracy: 0.9763\n",
            "Epoch 19/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.1071 - val_accuracy: 0.9800\n",
            "Epoch 20/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 0.1013 - val_accuracy: 0.9794\n",
            "Epoch 21/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1037 - val_accuracy: 0.9797\n",
            "Epoch 22/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.1060 - val_accuracy: 0.9793\n",
            "Epoch 23/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.1190 - val_accuracy: 0.9792\n",
            "Epoch 24/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1050 - val_accuracy: 0.9812\n",
            "Epoch 25/30\n",
            "600/600 [==============================] - 2s 3ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.1018 - val_accuracy: 0.9816\n",
            "Epoch 26/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.1129 - val_accuracy: 0.9783\n",
            "Epoch 27/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.1179 - val_accuracy: 0.9786\n",
            "Epoch 28/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0951 - val_accuracy: 0.9829\n",
            "Epoch 29/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.1238 - val_accuracy: 0.9802\n",
            "Epoch 30/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1280 - val_accuracy: 0.9806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAAFSOnkUytO",
        "colab_type": "text"
      },
      "source": [
        "## 5-Layer Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCCMlrkgUytP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-lmchEWUytT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "79119283-1baf-4d8a-cea0-a6a083d99c84"
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 317,450\n",
            "Trainable params: 317,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLp4Qk14UytW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2a8f4c1-148b-4cc9-9a03-e1f92d752d8a"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/30\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2472 - accuracy: 0.9273 - val_loss: 0.1125 - val_accuracy: 0.9651\n",
            "Epoch 2/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0965 - accuracy: 0.9709 - val_loss: 0.0845 - val_accuracy: 0.9738\n",
            "Epoch 3/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0660 - accuracy: 0.9794 - val_loss: 0.0905 - val_accuracy: 0.9728\n",
            "Epoch 4/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0505 - accuracy: 0.9835 - val_loss: 0.0954 - val_accuracy: 0.9711\n",
            "Epoch 5/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0399 - accuracy: 0.9872 - val_loss: 0.0795 - val_accuracy: 0.9784\n",
            "Epoch 6/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0318 - accuracy: 0.9897 - val_loss: 0.0878 - val_accuracy: 0.9749\n",
            "Epoch 7/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.0825 - val_accuracy: 0.9787\n",
            "Epoch 8/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.1031 - val_accuracy: 0.9765\n",
            "Epoch 9/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0840 - val_accuracy: 0.9788\n",
            "Epoch 10/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0933 - val_accuracy: 0.9770\n",
            "Epoch 11/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0833 - val_accuracy: 0.9801\n",
            "Epoch 12/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.1038 - val_accuracy: 0.9772\n",
            "Epoch 13/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 0.0986 - val_accuracy: 0.9765\n",
            "Epoch 14/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0170 - accuracy: 0.9946 - val_loss: 0.0837 - val_accuracy: 0.9812\n",
            "Epoch 15/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.0942 - val_accuracy: 0.9780\n",
            "Epoch 16/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0985 - val_accuracy: 0.9803\n",
            "Epoch 17/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0946 - val_accuracy: 0.9809\n",
            "Epoch 18/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.0985 - val_accuracy: 0.9787\n",
            "Epoch 19/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1128 - val_accuracy: 0.9777\n",
            "Epoch 20/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.0960 - val_accuracy: 0.9809\n",
            "Epoch 21/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0872 - val_accuracy: 0.9812\n",
            "Epoch 22/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1069 - val_accuracy: 0.9803\n",
            "Epoch 23/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.1136 - val_accuracy: 0.9790\n",
            "Epoch 24/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1048 - val_accuracy: 0.9806\n",
            "Epoch 25/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.1231 - val_accuracy: 0.9772\n",
            "Epoch 26/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1049 - val_accuracy: 0.9809\n",
            "Epoch 27/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.1181 - val_accuracy: 0.9832\n",
            "Epoch 28/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.1223 - val_accuracy: 0.9805\n",
            "Epoch 29/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9975 - val_loss: 0.1060 - val_accuracy: 0.9819\n",
            "Epoch 30/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.1086 - val_accuracy: 0.9813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QknPYbfxUytY",
        "colab_type": "text"
      },
      "source": [
        "## Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5JRtYQ1UytZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## model function\n",
        "drop_rate = 0.3\n",
        "\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(drop_rate))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(drop_rate))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(drop_rate))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dropout(drop_rate))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCrBVL1sUytb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "26090d03-b4b3-483f-d3c8-09f51f68fdfe"
      },
      "source": [
        "## Create model, compile & summary\n",
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 317,450\n",
            "Trainable params: 317,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Y2-0HNKgUytd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c73c3cba-8f61-4d49-a920-c39f11c7fa97"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS+30, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/60\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.4467 - accuracy: 0.8611 - val_loss: 0.1473 - val_accuracy: 0.9559\n",
            "Epoch 2/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.1874 - accuracy: 0.9481 - val_loss: 0.1121 - val_accuracy: 0.9666\n",
            "Epoch 3/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.1435 - accuracy: 0.9600 - val_loss: 0.0961 - val_accuracy: 0.9717\n",
            "Epoch 4/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.1228 - accuracy: 0.9654 - val_loss: 0.0831 - val_accuracy: 0.9763\n",
            "Epoch 5/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.1098 - accuracy: 0.9702 - val_loss: 0.0867 - val_accuracy: 0.9763\n",
            "Epoch 6/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0959 - accuracy: 0.9726 - val_loss: 0.0815 - val_accuracy: 0.9784\n",
            "Epoch 7/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0874 - accuracy: 0.9752 - val_loss: 0.0800 - val_accuracy: 0.9760\n",
            "Epoch 8/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9764 - val_loss: 0.0730 - val_accuracy: 0.9796\n",
            "Epoch 9/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0758 - accuracy: 0.9780 - val_loss: 0.0766 - val_accuracy: 0.9804\n",
            "Epoch 10/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0669 - accuracy: 0.9802 - val_loss: 0.0746 - val_accuracy: 0.9813\n",
            "Epoch 11/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0663 - accuracy: 0.9806 - val_loss: 0.0668 - val_accuracy: 0.9812\n",
            "Epoch 12/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0628 - accuracy: 0.9816 - val_loss: 0.0684 - val_accuracy: 0.9818\n",
            "Epoch 13/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0559 - accuracy: 0.9834 - val_loss: 0.0874 - val_accuracy: 0.9781\n",
            "Epoch 14/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0566 - accuracy: 0.9832 - val_loss: 0.0703 - val_accuracy: 0.9813\n",
            "Epoch 15/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0534 - accuracy: 0.9844 - val_loss: 0.0740 - val_accuracy: 0.9823\n",
            "Epoch 16/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0510 - accuracy: 0.9854 - val_loss: 0.0666 - val_accuracy: 0.9826\n",
            "Epoch 17/60\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.0703 - val_accuracy: 0.9818\n",
            "Epoch 18/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0461 - accuracy: 0.9862 - val_loss: 0.0729 - val_accuracy: 0.9814\n",
            "Epoch 19/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.0655 - val_accuracy: 0.9834\n",
            "Epoch 20/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0433 - accuracy: 0.9873 - val_loss: 0.0712 - val_accuracy: 0.9827\n",
            "Epoch 21/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 0.0716 - val_accuracy: 0.9822\n",
            "Epoch 22/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0402 - accuracy: 0.9881 - val_loss: 0.0767 - val_accuracy: 0.9815\n",
            "Epoch 23/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0424 - accuracy: 0.9880 - val_loss: 0.0748 - val_accuracy: 0.9830\n",
            "Epoch 24/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0400 - accuracy: 0.9882 - val_loss: 0.0725 - val_accuracy: 0.9827\n",
            "Epoch 25/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0366 - accuracy: 0.9891 - val_loss: 0.0807 - val_accuracy: 0.9823\n",
            "Epoch 26/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0379 - accuracy: 0.9887 - val_loss: 0.0683 - val_accuracy: 0.9838\n",
            "Epoch 27/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0374 - accuracy: 0.9898 - val_loss: 0.0694 - val_accuracy: 0.9831\n",
            "Epoch 28/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0368 - accuracy: 0.9893 - val_loss: 0.0628 - val_accuracy: 0.9844\n",
            "Epoch 29/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0373 - accuracy: 0.9888 - val_loss: 0.0701 - val_accuracy: 0.9827\n",
            "Epoch 30/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0339 - accuracy: 0.9901 - val_loss: 0.0707 - val_accuracy: 0.9836\n",
            "Epoch 31/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 0.0747 - val_accuracy: 0.9829\n",
            "Epoch 32/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0339 - accuracy: 0.9902 - val_loss: 0.0860 - val_accuracy: 0.9843\n",
            "Epoch 33/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.0748 - val_accuracy: 0.9832\n",
            "Epoch 34/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0322 - accuracy: 0.9909 - val_loss: 0.0860 - val_accuracy: 0.9831\n",
            "Epoch 35/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0287 - accuracy: 0.9915 - val_loss: 0.0839 - val_accuracy: 0.9831\n",
            "Epoch 36/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0311 - accuracy: 0.9907 - val_loss: 0.0810 - val_accuracy: 0.9836\n",
            "Epoch 37/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.0732 - val_accuracy: 0.9846\n",
            "Epoch 38/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 0.0854 - val_accuracy: 0.9844\n",
            "Epoch 39/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0765 - val_accuracy: 0.9848\n",
            "Epoch 40/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0278 - accuracy: 0.9915 - val_loss: 0.0881 - val_accuracy: 0.9828\n",
            "Epoch 41/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0313 - accuracy: 0.9910 - val_loss: 0.0872 - val_accuracy: 0.9827\n",
            "Epoch 42/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0290 - accuracy: 0.9920 - val_loss: 0.0764 - val_accuracy: 0.9826\n",
            "Epoch 43/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.0813 - val_accuracy: 0.9836\n",
            "Epoch 44/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0284 - accuracy: 0.9918 - val_loss: 0.0845 - val_accuracy: 0.9835\n",
            "Epoch 45/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0289 - accuracy: 0.9921 - val_loss: 0.0819 - val_accuracy: 0.9824\n",
            "Epoch 46/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.0818 - val_accuracy: 0.9842\n",
            "Epoch 47/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0762 - val_accuracy: 0.9846\n",
            "Epoch 48/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0263 - accuracy: 0.9926 - val_loss: 0.0834 - val_accuracy: 0.9836\n",
            "Epoch 49/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.0837 - val_accuracy: 0.9845\n",
            "Epoch 50/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 0.1001 - val_accuracy: 0.9845\n",
            "Epoch 51/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.0879 - val_accuracy: 0.9852\n",
            "Epoch 52/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.0893 - val_accuracy: 0.9852\n",
            "Epoch 53/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.0845 - val_accuracy: 0.9847\n",
            "Epoch 54/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.1030 - val_accuracy: 0.9821\n",
            "Epoch 55/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0253 - accuracy: 0.9926 - val_loss: 0.0864 - val_accuracy: 0.9839\n",
            "Epoch 56/60\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 0.0885 - val_accuracy: 0.9848\n",
            "Epoch 57/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.0970 - val_accuracy: 0.9836\n",
            "Epoch 58/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.0926 - val_accuracy: 0.9839\n",
            "Epoch 59/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 0.0881 - val_accuracy: 0.9855\n",
            "Epoch 60/60\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0853 - val_accuracy: 0.9844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsmTVN1YUytg",
        "colab_type": "text"
      },
      "source": [
        "## L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmp8fH2CUyth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_weight = 0.00003\n",
        "\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "    model.add(keras.layers.Dense(256, activation='relu',\n",
        "                                kernel_regularizer=keras.regularizers.l2(reg_weight)))\n",
        "    model.add(keras.layers.Dense(256, activation='relu',\n",
        "                                kernel_regularizer=keras.regularizers.l2(reg_weight)))\n",
        "    model.add(keras.layers.Dense(128, activation='relu',\n",
        "                                kernel_regularizer=keras.regularizers.l2(reg_weight)))\n",
        "    model.add(keras.layers.Dense(128, activation='relu',\n",
        "                                kernel_regularizer=keras.regularizers.l2(reg_weight)))    \n",
        "    model.add(keras.layers.Dense(10, activation='softmax',\n",
        "                                kernel_regularizer=keras.regularizers.l2(reg_weight)))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgXE1SveUytk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "010b831d-eba5-4d62-964c-680952a8d96c"
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 317,450\n",
            "Trainable params: 317,450\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORICNJEGUytm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9489c50a-1557-4534-992b-392b473217f1"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/30\n",
            "600/600 [==============================] - 3s 6ms/step - loss: 0.2716 - accuracy: 0.9270 - val_loss: 0.1417 - val_accuracy: 0.9632\n",
            "Epoch 2/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.1245 - accuracy: 0.9700 - val_loss: 0.1198 - val_accuracy: 0.9704\n",
            "Epoch 3/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0928 - accuracy: 0.9795 - val_loss: 0.1168 - val_accuracy: 0.9730\n",
            "Epoch 4/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0820 - accuracy: 0.9833 - val_loss: 0.1136 - val_accuracy: 0.9736\n",
            "Epoch 5/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0702 - accuracy: 0.9871 - val_loss: 0.1194 - val_accuracy: 0.9729\n",
            "Epoch 6/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0665 - accuracy: 0.9892 - val_loss: 0.1113 - val_accuracy: 0.9791\n",
            "Epoch 7/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0639 - accuracy: 0.9898 - val_loss: 0.1156 - val_accuracy: 0.9764\n",
            "Epoch 8/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0606 - accuracy: 0.9911 - val_loss: 0.1178 - val_accuracy: 0.9769\n",
            "Epoch 9/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0611 - accuracy: 0.9907 - val_loss: 0.1161 - val_accuracy: 0.9788\n",
            "Epoch 10/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0601 - accuracy: 0.9916 - val_loss: 0.1240 - val_accuracy: 0.9749\n",
            "Epoch 11/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0561 - accuracy: 0.9931 - val_loss: 0.1140 - val_accuracy: 0.9788\n",
            "Epoch 12/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0535 - accuracy: 0.9939 - val_loss: 0.1270 - val_accuracy: 0.9762\n",
            "Epoch 13/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0534 - accuracy: 0.9940 - val_loss: 0.1184 - val_accuracy: 0.9787\n",
            "Epoch 14/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0521 - accuracy: 0.9942 - val_loss: 0.1242 - val_accuracy: 0.9769\n",
            "Epoch 15/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0531 - accuracy: 0.9936 - val_loss: 0.1057 - val_accuracy: 0.9819\n",
            "Epoch 16/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0517 - accuracy: 0.9938 - val_loss: 0.1033 - val_accuracy: 0.9808\n",
            "Epoch 17/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0492 - accuracy: 0.9950 - val_loss: 0.1159 - val_accuracy: 0.9803\n",
            "Epoch 18/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0493 - accuracy: 0.9949 - val_loss: 0.1018 - val_accuracy: 0.9828\n",
            "Epoch 19/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0476 - accuracy: 0.9951 - val_loss: 0.1207 - val_accuracy: 0.9794\n",
            "Epoch 20/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0473 - accuracy: 0.9951 - val_loss: 0.1142 - val_accuracy: 0.9812\n",
            "Epoch 21/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0480 - accuracy: 0.9949 - val_loss: 0.1077 - val_accuracy: 0.9810\n",
            "Epoch 22/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0459 - accuracy: 0.9953 - val_loss: 0.1040 - val_accuracy: 0.9829\n",
            "Epoch 23/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0450 - accuracy: 0.9959 - val_loss: 0.1227 - val_accuracy: 0.9776\n",
            "Epoch 24/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0450 - accuracy: 0.9962 - val_loss: 0.1151 - val_accuracy: 0.9810\n",
            "Epoch 25/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0438 - accuracy: 0.9962 - val_loss: 0.0982 - val_accuracy: 0.9834\n",
            "Epoch 26/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0423 - accuracy: 0.9964 - val_loss: 0.1104 - val_accuracy: 0.9808\n",
            "Epoch 27/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0441 - accuracy: 0.9957 - val_loss: 0.1101 - val_accuracy: 0.9812\n",
            "Epoch 28/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0421 - accuracy: 0.9961 - val_loss: 0.1120 - val_accuracy: 0.9819\n",
            "Epoch 29/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0428 - accuracy: 0.9959 - val_loss: 0.1094 - val_accuracy: 0.9819\n",
            "Epoch 30/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0419 - accuracy: 0.9962 - val_loss: 0.1021 - val_accuracy: 0.9829\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMqivarTUyto",
        "colab_type": "text"
      },
      "source": [
        "## Batch Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-U0XkH7Uytp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "    model.add(keras.layers.Dense(256))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dense(256))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dense(128))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dense(128))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.ReLU())\n",
        "    model.add(keras.layers.Dense(10))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Softmax())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZPccFskUyts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "0533fbb8-5e2c-4052-96af-e4e6711e2baf"
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 320,562\n",
            "Trainable params: 319,006\n",
            "Non-trainable params: 1,556\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmVPab1-Uytv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fc291ff-9bb9-4853-9850-933ca530d2d6"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/30\n",
            "600/600 [==============================] - 5s 9ms/step - loss: 0.3813 - accuracy: 0.9372 - val_loss: 0.1941 - val_accuracy: 0.9723\n",
            "Epoch 2/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.1658 - accuracy: 0.9713 - val_loss: 0.1180 - val_accuracy: 0.9749\n",
            "Epoch 3/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.1055 - accuracy: 0.9800 - val_loss: 0.0955 - val_accuracy: 0.9770\n",
            "Epoch 4/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0778 - accuracy: 0.9833 - val_loss: 0.0933 - val_accuracy: 0.9757\n",
            "Epoch 5/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0577 - accuracy: 0.9871 - val_loss: 0.0793 - val_accuracy: 0.9793\n",
            "Epoch 6/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0485 - accuracy: 0.9884 - val_loss: 0.0650 - val_accuracy: 0.9823\n",
            "Epoch 7/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0402 - accuracy: 0.9896 - val_loss: 0.0677 - val_accuracy: 0.9812\n",
            "Epoch 8/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0350 - accuracy: 0.9909 - val_loss: 0.0693 - val_accuracy: 0.9807\n",
            "Epoch 9/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0297 - accuracy: 0.9921 - val_loss: 0.0710 - val_accuracy: 0.9814\n",
            "Epoch 10/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.0728 - val_accuracy: 0.9792\n",
            "Epoch 11/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 0.0693 - val_accuracy: 0.9806\n",
            "Epoch 12/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0215 - accuracy: 0.9944 - val_loss: 0.0638 - val_accuracy: 0.9817\n",
            "Epoch 13/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.0615 - val_accuracy: 0.9827\n",
            "Epoch 14/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.0617 - val_accuracy: 0.9830\n",
            "Epoch 15/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0172 - accuracy: 0.9953 - val_loss: 0.0603 - val_accuracy: 0.9845\n",
            "Epoch 16/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 0.0590 - val_accuracy: 0.9833\n",
            "Epoch 17/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0681 - val_accuracy: 0.9814\n",
            "Epoch 18/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0669 - val_accuracy: 0.9826\n",
            "Epoch 19/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.0614 - val_accuracy: 0.9837\n",
            "Epoch 20/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0732 - val_accuracy: 0.9800\n",
            "Epoch 21/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0719 - val_accuracy: 0.9821\n",
            "Epoch 22/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.0630 - val_accuracy: 0.9830\n",
            "Epoch 23/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0648 - val_accuracy: 0.9839\n",
            "Epoch 24/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0713 - val_accuracy: 0.9832\n",
            "Epoch 25/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0688 - val_accuracy: 0.9828\n",
            "Epoch 26/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0616 - val_accuracy: 0.9853\n",
            "Epoch 27/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0718 - val_accuracy: 0.9820\n",
            "Epoch 28/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0802 - val_accuracy: 0.9810\n",
            "Epoch 29/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 0.0641 - val_accuracy: 0.9836\n",
            "Epoch 30/30\n",
            "600/600 [==============================] - 4s 7ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0675 - val_accuracy: 0.9831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWIGs6HPUytx",
        "colab_type": "text"
      },
      "source": [
        "# Learning Rate Decay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GabczA5XUyty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## model function\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f392BnZUyt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3bZMNQEUyt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate,\n",
        "                                                          decay_steps=steps_per_epoch*10,\n",
        "                                                          decay_rate=0.5,\n",
        "                                                          staircase=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq2DLqjZUyt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(lr_schedule),\n",
        "                 loss = 'categorical_crossentropy',\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYmTxwTCUyt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5bd32015-f92f-424a-c465-420f28cc9d33"
      },
      "source": [
        "## Training\n",
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/30\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2458 - accuracy: 0.9262 - val_loss: 0.1244 - val_accuracy: 0.9626\n",
            "Epoch 2/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0942 - accuracy: 0.9704 - val_loss: 0.0826 - val_accuracy: 0.9744\n",
            "Epoch 3/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0652 - accuracy: 0.9796 - val_loss: 0.0719 - val_accuracy: 0.9767\n",
            "Epoch 4/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0510 - accuracy: 0.9841 - val_loss: 0.0816 - val_accuracy: 0.9748\n",
            "Epoch 5/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.0942 - val_accuracy: 0.9706\n",
            "Epoch 6/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.9887 - val_loss: 0.0777 - val_accuracy: 0.9775\n",
            "Epoch 7/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.0756 - val_accuracy: 0.9791\n",
            "Epoch 8/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0712 - val_accuracy: 0.9815\n",
            "Epoch 9/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.9934 - val_loss: 0.0932 - val_accuracy: 0.9759\n",
            "Epoch 10/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0952 - val_accuracy: 0.9757\n",
            "Epoch 11/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0682 - val_accuracy: 0.9848\n",
            "Epoch 12/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0778 - val_accuracy: 0.9834\n",
            "Epoch 13/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0977 - val_accuracy: 0.9807\n",
            "Epoch 14/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0902 - val_accuracy: 0.9816\n",
            "Epoch 15/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0883 - val_accuracy: 0.9837\n",
            "Epoch 16/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0057 - accuracy: 0.9981 - val_loss: 0.0809 - val_accuracy: 0.9822\n",
            "Epoch 17/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0931 - val_accuracy: 0.9829\n",
            "Epoch 18/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0846 - val_accuracy: 0.9826\n",
            "Epoch 19/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1053 - val_accuracy: 0.9824\n",
            "Epoch 20/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0857 - val_accuracy: 0.9823\n",
            "Epoch 21/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0779 - val_accuracy: 0.9850\n",
            "Epoch 22/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.6310e-04 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9856\n",
            "Epoch 23/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 6.6803e-05 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9855\n",
            "Epoch 24/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 4.4650e-05 - accuracy: 1.0000 - val_loss: 0.0836 - val_accuracy: 0.9858\n",
            "Epoch 25/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 3.1271e-05 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9859\n",
            "Epoch 26/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 2.2310e-05 - accuracy: 1.0000 - val_loss: 0.0876 - val_accuracy: 0.9861\n",
            "Epoch 27/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.6051e-05 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9863\n",
            "Epoch 28/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.1513e-05 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9864\n",
            "Epoch 29/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 8.1886e-06 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9864\n",
            "Epoch 30/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 5.9061e-06 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOj6NDiuUyt_",
        "colab_type": "text"
      },
      "source": [
        "## Learning Rate Schedule"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylJ1Fn5dUyt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## model function\n",
        "def create_model():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dense(256, activation='relu'))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o48qK2vUyuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb8WW-PeUyuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## learning rate schedule에 대한 함수 - step decay example\n",
        "def lr_schedule_fn(epoch):\n",
        "    if epoch < 10:        \n",
        "        return learning_rate\n",
        "    elif epoch <20:\n",
        "        return learning_rate * 0.1\n",
        "    else:\n",
        "        return learning_rate * 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOAZUqg4UyuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## learning rate schedule에 대한 함수 - exponential decay example\n",
        "#def lr_schedule_fn(epoch):\n",
        "#    return learning_rate * 0.01**(epoch/N_EPOCHS) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQRJIvBVUyuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## callback을 이용한 learning rate scheduler 생성\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(lr_schedule_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5EvzXnCUyuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6JQQFjnUyuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "777b96bb-6e1c-45f1-caf9-f43691d07a56"
      },
      "source": [
        "history = model.fit(train_dataset, epochs=N_EPOCHS, steps_per_epoch=steps_per_epoch, \n",
        "                    validation_data=test_dataset, validation_steps=validation_steps,\n",
        "                    callbacks=[lr_scheduler])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 600 steps, validate for 100 steps\n",
            "Epoch 1/30\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.2455 - accuracy: 0.9278 - val_loss: 0.1193 - val_accuracy: 0.9629\n",
            "Epoch 2/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0949 - accuracy: 0.9706 - val_loss: 0.0946 - val_accuracy: 0.9709\n",
            "Epoch 3/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0651 - accuracy: 0.9794 - val_loss: 0.0840 - val_accuracy: 0.9762\n",
            "Epoch 4/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0491 - accuracy: 0.9848 - val_loss: 0.0744 - val_accuracy: 0.9777\n",
            "Epoch 5/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0390 - accuracy: 0.9872 - val_loss: 0.0816 - val_accuracy: 0.9770\n",
            "Epoch 6/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0753 - val_accuracy: 0.9817\n",
            "Epoch 7/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0948 - val_accuracy: 0.9755\n",
            "Epoch 8/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0868 - val_accuracy: 0.9775\n",
            "Epoch 9/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0753 - val_accuracy: 0.9797\n",
            "Epoch 10/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0193 - accuracy: 0.9938 - val_loss: 0.0867 - val_accuracy: 0.9795\n",
            "Epoch 11/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0732 - val_accuracy: 0.9835\n",
            "Epoch 12/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0713 - val_accuracy: 0.9843\n",
            "Epoch 13/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0746 - val_accuracy: 0.9842\n",
            "Epoch 14/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 9.0788e-04 - accuracy: 0.9999 - val_loss: 0.0754 - val_accuracy: 0.9847\n",
            "Epoch 15/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 6.2427e-04 - accuracy: 0.9999 - val_loss: 0.0796 - val_accuracy: 0.9844\n",
            "Epoch 16/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 4.0575e-04 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9842\n",
            "Epoch 17/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 2.6838e-04 - accuracy: 1.0000 - val_loss: 0.0854 - val_accuracy: 0.9845\n",
            "Epoch 18/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.9558e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9846\n",
            "Epoch 19/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.3326e-04 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9842\n",
            "Epoch 20/30\n",
            "600/600 [==============================] - 3s 4ms/step - loss: 1.1019e-04 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 0.9847\n",
            "Epoch 21/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 1.1572e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9851\n",
            "Epoch 22/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 9.1085e-05 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9847\n",
            "Epoch 23/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 7.7398e-05 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9846\n",
            "Epoch 24/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 6.4705e-05 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9846\n",
            "Epoch 25/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 5.5708e-05 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9846\n",
            "Epoch 26/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 4.7895e-05 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9847\n",
            "Epoch 27/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 4.1447e-05 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9847\n",
            "Epoch 28/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 3.6391e-05 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9848\n",
            "Epoch 29/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 3.1978e-05 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9845\n",
            "Epoch 30/30\n",
            "600/600 [==============================] - 2s 4ms/step - loss: 2.7927e-05 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMYl9svEZ19P",
        "colab_type": "text"
      },
      "source": [
        "## Find Your Best Model for MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BVoaiXlUyus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}